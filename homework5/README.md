# Промежуточная аттестация

## Введение
Сравнение классификаторов

Суть задания состоит в том, чтобы сравнить различные классификаторы на наборе данных Extended MNIST https://www.nist.gov/itl/products-and-services/emnist-dataset, который содержит монохромные изображения латинских букв. На каждом изображении находится по одной букве в низком разрешении (28 на 28 пикселей).

Результат отправляется в виде файла CSV 

```
Id,Category
1,12
2,14
3,10
4,15
5,12

```

Где Id - номер сэмпла, начиная с 1, а Category - предсказанный символ(от 1 до 26)


## Методика

В процессе исследования будут проверены несколько классификаторов с различными настройками.

## Константный классификатор

Проще не придумаешь. Для любого входа выдаем константный класс. В среднем ожидается точность в районе 1/26.

Получена точность *0.05495*

## Наивная линейная регрессия

Учитывая, что классы представлены числами, делано сильное предположение, что может подойти линейная регрессия в качестве классификатора.

Получена точность *0.06734*. Результат показывает, что модель не обладает предсказательной силой.

## KNN

Учитывая недостаток вычислительных мощностей, для KNN сразу было применено сокращение размерности, когда в изображении 28х28 брался каждый второй пиксел по каждой из осей. Сокращение размерности 28x28 -> 14x14 в 4 раза.

Получена точность *0.83513*.

Также проверено еще большее сокращение размерности 28x28 -> 7x7 методом skimage.measure.block_reduce и np.max(max pooling). 

Получена точность *0.7995* 

Далее, сократили битность входных значений до 1.

Получена точность *0.7254*

Сокращение битности в данном случае оказало заметный результат, но при этом, точность все еще лучше решения  baseline. Учитывая, что входной поток данных уменьшился в 128 раз, в некоторых задачах такое сокращение может быть оправдано.